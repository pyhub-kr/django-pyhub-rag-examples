import os
from pathlib import Path
from typing import Optional, Union

from dotenv import load_dotenv
import streamlit as st

from pyhub.llm import LLM
from pyhub.rag.db.sqlite_vec import similarity_search


def main(
    db_path: Union[Path, str],
    table_name: str,
    system_prompt: str,
    openai_api_key: Optional[str] = None,
    anthropic_api_key: Optional[str] = None,
):
    default_query = (
        "ìˆ˜ì¶œí•˜ëŠ” ê²½ìš° ì˜ì„¸ìœ¨ ì²¨ë¶€ ì„œë¥˜ë¡œ ìˆ˜ì¶œì‹¤ì ëª…ì„¸ì„œê°€ ì—†ëŠ” ê²½ìš° í•´ê²° ë°©ë²•"
    )

    st.set_page_config(layout="wide")
    st.title("ğŸ“š RAG Demo")
    with st.container():
        search_query = st.text_input(
            "ğŸ” ê²€ìƒ‰ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
            placeholder=default_query,
        ).strip()
        search_button = st.button("ìœ ì‚¬ ë¬¸ì„œ ì°¾ê¸°")

    if search_button:
        if not search_query:
            search_query = default_query

        st.markdown(f"### ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë‚´ìš©ì˜ ë¬¸ì„œ")

        with st.spinner("ì°¾ëŠ” ì¤‘ ..."):
            doc_list = similarity_search(
                db_path=db_path,
                table_name=table_name,
                query=search_query,
                embedding_model="text-embedding-3-large",
                api_key=openai_api_key,
            )
        st.markdown(f"{len(doc_list)} ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        if doc_list:
            for doc in doc_list:
                title = " ".join(doc.page_content.splitlines()[:3])
                title = title.replace("##", "/")

                with st.expander(title.strip()):
                    st.markdown(doc.page_content)
                    st.markdown(doc.metadata)
        else:
            st.info("No documents found matching your search criteria.")

        # ì§€ì‹ + ì§ˆì˜ë¥¼ LLMì—ê²Œ ì „ë‹¬í•˜ì—¬ ì‘ë‹µ ìƒì„±
        ì§€ì‹ = str(doc_list)
        chat_llm = LLM.create(
            model="claude-3-7-sonnet-latest",
            api_key=anthropic_api_key,
            # model="gpt-4o-mini",
            # api_key=openai_api_key,
            system_prompt=system_prompt + f"\n\n<context>{ì§€ì‹}</context>",
            max_tokens=4000,
        )

        st.markdown(f"### LLM ì‘ë‹µ (ëª¨ë¸: {chat_llm.model})")

        with st.spinner("LLM ì‘ë‹µ ìƒì„± ì¤‘ ..."):
            # ì‘ë‹µì„ í‘œì‹œí•  ë¹ˆ ì»´í¬ë„ŒíŠ¸ ìƒì„±
            response_container = st.empty()

            text = ""
            for reply in chat_llm.reply(f"Question: {search_query}", stream=True):
                text += reply.text
                # ëˆ„ì ëœ í…ìŠ¤íŠ¸ë¡œ ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸
                response_container.markdown(text)

    # Footer
    st.markdown("---")
    st.markdown(
        """
<div style="text-align: center; color: gray; font-size: 0.8em;">
íŒŒì´ì¬ì‚¬ë‘ë°© (<a href="mailto:me@pyhub.kr">me@pyhub.kr</a>)
</div>
        """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    load_dotenv()

    try:
        with open("system_prompt_taxlaw.txt", "rt", encoding="utf-8") as f:
            loaded_system_prompt = f.read()
    except IOError:
        loaded_system_prompt = None

    main(
        db_path="./taxlaw-sample.sqlite3",
        table_name="documents",
        system_prompt=loaded_system_prompt,
        # .env íŒŒì¼ì—ì„œ ë¡œë“œëœ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
    )
